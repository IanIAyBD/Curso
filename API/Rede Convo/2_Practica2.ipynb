{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Practica2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H0RetZ8RUDLr"
      },
      "source": [
        "# **Práctica 2**\n",
        "\n",
        "En esta práctica vamos a ver como podríamos trabajar con redes neuronales totalmente conectadas en imagen. Veremos cuales son las limitaciones de emplear este tipo de arquitecturas para trabajar con imágenes.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mc0TTORUkpi"
      },
      "source": [
        "En primer lugar vamos a trabajar con el dataset MNIST para clasificación de imágenes de dígitos numéricos. Para ello seguiremos los siguientes pasos:\n",
        "\n",
        "\n",
        "\n",
        "1.   Descargaremos las imágenes y las visualizaremos\n",
        "2.   Pre-procesaremos los datos.\n",
        "3.   Diseñaremos la arquitectura.\n",
        "4.   Entrenaremos la red.\n",
        "5.   Evaluaremos el modelo entrenado.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWhJoqzBVB5J"
      },
      "source": [
        "# 1. Descaga de las imágenes y visualización"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RzV61jpmTYkb"
      },
      "source": [
        "# Importamos la base de datos de las propias de keras\n",
        "from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# Descargamos el dataset diferenciando entre conjunto de entrenamiento y validación/test\n",
        "(X_train, y_train), (X_testval, y_testval) = mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-mbeVX0VjMK"
      },
      "source": [
        "# Analizamos la base de datos descargada\n",
        "# Tamaño de las imágenes y número de muestras\n",
        "print(\"Tamaño imágenes entrenamiento: \", X_train.shape)\n",
        "print(\"Tamaño etiquetas entrenamiento: \", y_train.shape)\n",
        "print(\"Tamaño imágenes validación/test: \", X_testval.shape)\n",
        "print(\"Tamaño etiquetas validación/test: \", y_testval.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_V82xxpWHVb"
      },
      "source": [
        "# Tipo de datos\n",
        "print(\"Tipo datos imágenes entrenamiento: \", X_train.dtype)\n",
        "print(\"Tipo datos etiquetas entrenamiento: \", y_train.dtype)\n",
        "print(\"Tipo datos imágenes validación/test: \", X_testval.dtype)\n",
        "print(\"Tipo datos etiquetas validación/test: \", y_testval.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KlTXs_JWPbR"
      },
      "source": [
        "# Rango de valores de las imágenes\n",
        "print(\"Valor mínimo imágenes entrenamiento: \", X_train.min())\n",
        "print(\"Valor máximo imágenes entrenamiento: \", X_train.max())\n",
        "print(\"Valor mínimo imágenes validación/test: \", X_testval.min())\n",
        "print(\"Valor máximo imágenes validación/test: \", X_testval.max())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "608DcGpLXl15"
      },
      "source": [
        "# Etiquetas de las particiones\n",
        "import numpy as np\n",
        "\n",
        "print(\"Etiquetas entrenamiento: \", np.unique(y_train))\n",
        "print(\"Etiquetas validación/test: \", np.unique(y_testval))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CW1JYISWX6Qa"
      },
      "source": [
        "# Visualización de las imágenes\n",
        "import matplotlib.pyplot as plt\n",
        "# Configuramos tamaño de las imágenes para una correcta visualización\n",
        "plt.rcParams['figure.figsize'] = (10, 10)\n",
        "# Mostramos 9 imágenes con su etiqueta correspondiente\n",
        "for i in range(9):\n",
        "  plt.subplot(3, 3, i+1)\n",
        "  plt.imshow(X_train[i], cmap='gray')\n",
        "  plt.title(f'Clase {y_train[i]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mYU2_0K0Y3hk"
      },
      "source": [
        "# 2. Pre-proceso de los datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7cw65IwYy_0"
      },
      "source": [
        "# Para trabajar con redes neuronales totalmente conectadas no podemos trabajar con matrices 2D, debemos convertir la imagen a vector 1D\n",
        "X_train_vector = X_train.reshape(X_train.shape[0], X_train.shape[1]*X_train.shape[2])\n",
        "X_testval_vector = X_testval.reshape(X_testval.shape[0], X_testval.shape[1]*X_testval.shape[2])\n",
        "print(\"Nuevo tamaño datos entrenamiento: \", X_train_vector.shape)\n",
        "print(\"Nuevo tamaño datos validación/test: \", X_testval_vector.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6eBfheuZ_w6"
      },
      "source": [
        "# Las redes neuronales trabajan mejor con valores entre 0-1. Por lo que vamos a convertir el rango\n",
        "\n",
        "# Primero convertimos las imágenes a float\n",
        "X_train_vector = X_train_vector.astype('float32')\n",
        "X_testval_vector = X_testval_vector.astype('float32')\n",
        "print('Tipo datos entrenamiento: ', X_train_vector.dtype)\n",
        "print('Tipo datos validación/test: ', X_testval_vector.dtype)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSKwN9goavmZ"
      },
      "source": [
        "# Cambiamos rango de las imágenes\n",
        "X_train_vector /= 255\n",
        "X_testval_vector /= 255\n",
        "print(\"Rango datos entrenamiento: [\", X_train_vector.min(), ', ', X_train_vector.max(), ']')\n",
        "print(\"Rango datos validación/test: [\", X_testval_vector.min(), ', ', X_testval_vector.max(), ']')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwCkZqtebJNR"
      },
      "source": [
        "# Convertimos etiquetas a codificación one-hot\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "num_clases = len(np.unique(y_train))\n",
        "y_train_cod = to_categorical(y_train, num_clases)\n",
        "y_testval_cod = to_categorical(y_testval, num_clases)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-bCirGpcF0B"
      },
      "source": [
        "print(\"Tamaño etiquetas entrenamiento: \", y_train_cod.shape)\n",
        "print(\"Tamaño etiquetas validación/test: \", y_testval_cod.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLFnhlMDcdCu"
      },
      "source": [
        "# Dividimos conjunto de datos de validación/test en 2 subconjuntos\n",
        "samples_test_nb = int(X_testval.shape[0]/2)\n",
        "X_val = X_testval_vector[:samples_test_nb]\n",
        "y_val = y_testval_cod[:samples_test_nb]\n",
        "X_test = X_testval_vector[samples_test_nb:]\n",
        "y_test = y_testval_cod[samples_test_nb:]\n",
        "\n",
        "print(\"Muestras validación: \", X_val.shape)\n",
        "print(\"Muestras test: \", X_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVYvjZjRdGvI"
      },
      "source": [
        "# 3. Diseñamos la arquitectura\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQcYWFXAdFJd"
      },
      "source": [
        "# Importamos dependencias\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KyWnx5pNd3_b"
      },
      "source": [
        "# Definimos la arquitectura\n",
        "# Definimos arquitectura\n",
        "input_layer = Input(shape=(X_train_vector.shape[1],))\n",
        "hidden_layer = Dense(32, activation=\"relu\")(input_layer)\n",
        "output_layer = Dense(num_clases, activation=\"softmax\")(hidden_layer)\n",
        "\n",
        "model = Model(inputs=input_layer, outputs=output_layer)\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ehdQg2sceUkm"
      },
      "source": [
        "# Compilamos el modelo\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\",\n",
        "              metrics=[\"accuracy\"])"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuO7Sypvetf3"
      },
      "source": [
        "# 4. Entrenamiento de un modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ONkOOPQer3k"
      },
      "source": [
        "history = model.fit(X_train_vector, y_train_cod, epochs=20, batch_size=128,\n",
        "                    validation_data=(X_val, y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEbi2c1Ggb0c"
      },
      "source": [
        "Cosas a observar:\n",
        "\n",
        "Métricas entrenamiento\n",
        "Métricas validacón\n",
        "¿Sobreajuste?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "whQQnSA9gGJ7"
      },
      "source": [
        "# Visualizamos la precisión\n",
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Precisión modelo')\n",
        "plt.ylabel('Precisión')\n",
        "plt.xlabel('Época')\n",
        "plt.ylim(0,1)\n",
        "plt.legend(['Entrenamiento', 'Validación'], loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ygwwFTrxgew7"
      },
      "source": [
        "# Visualizamos pérdidas\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Pérdidas modelo')\n",
        "plt.ylabel('Pérdidas')\n",
        "plt.xlabel('Época')\n",
        "plt.legend(['Entrenamiento', 'Validación'], loc=\"upper left\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLqG7g5xgtIg"
      },
      "source": [
        "# Guardamos el modelo\n",
        "from pathlib import Path\n",
        "path_modelos = Path('./modelos')\n",
        "path_modelos.mkdir(exist_ok=True)\n",
        "model.save(path_modelos / 'model_mnist.h5')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VS_2uFMphIid"
      },
      "source": [
        "# 5. Evaluamos el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wREq19jahFS6"
      },
      "source": [
        "# Sacamos métricas sobre nuestro conjunto de test\n",
        "metrics = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(\"Precision test: \", metrics[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak9Mpndohdds"
      },
      "source": [
        "# Obtenemos predicciones \n",
        "prediccion = model.predict(X_test)\n",
        "# Cogemos la clase con mayor probabilidad\n",
        "prediccion = np.argmax(prediccion, axis=1)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydaKcZBDiW6N"
      },
      "source": [
        "# Deshacemos codificación one-hot en conjunto de test\n",
        "y_test_clases = np.argmax(y_test, axis=1)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-xGq2-EijVC"
      },
      "source": [
        "# Detectamos imágenes correctamente clasificadas\n",
        "correct_index = np.nonzero(prediccion == y_test_clases)[0]"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUhnUxgBiv_r"
      },
      "source": [
        "# Detectamos imágenes incorrectamente clasificadas\n",
        "incorrect_index = np.nonzero(prediccion != y_test_clases)[0]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpSLcnAli48F"
      },
      "source": [
        "# Mostramos imágenes correctamente clasificadas\n",
        "plt.figure()\n",
        "for i, correct in enumerate(correct_index[:9]):\n",
        "  plt.subplot(3, 3, i+1)\n",
        "  plt.imshow(X_test[correct].reshape(28,28), cmap='gray')\n",
        "  plt.title(f'Real {y_test_clases[correct]}, Predicha {prediccion[correct]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ua1pLyTTjwCg"
      },
      "source": [
        "# Mostramos imágenes incorrectamente clasificadas\n",
        "plt.figure()\n",
        "for i, incorrect in enumerate(incorrect_index[:9]):\n",
        "  plt.subplot(3, 3, i+1)\n",
        "  plt.imshow(X_test[incorrect].reshape(28,28), cmap='gray')\n",
        "  plt.title(f'Real {y_test_clases[incorrect]}, Predicha {prediccion[incorrect]}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACTQQG5xddc4"
      },
      "source": [
        "# Ejercicio 1: Probamos diferentes funciones de activación\n",
        "\n",
        "Analizamos cómo afecta el uso de diferentes funciones de activación en la capa oculta. Probamos las siguientes:\n",
        "\n",
        "*   Sin función de activación\n",
        "*   Sigmoid\n",
        "*   Tanh\n",
        "*   Relu\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nr3wXVI15wvD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fW1RIZ43lR7d"
      },
      "source": [
        "# Ejercicio 2: Creamos un modelo más complejo\n",
        "Para aumentar la complejidad del modelo añadimos una capa oculta de 512 neuronas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drSXozl45wBK"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7C9hCFknFSA"
      },
      "source": [
        "# Ejercicio 3: Entrenamos un modelo con la base de datos CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcZjARMQ51jU"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}